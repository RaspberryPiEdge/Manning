{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxpEEoJL5odf",
        "outputId": "de704f33-5ccc-4415-b293-721b245de45b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 8s 872ms/step - loss: 0.3218 - accuracy: 0.8750 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 5s 832ms/step - loss: 0.0075 - accuracy: 0.9946 - val_loss: 6.1389e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 5s 850ms/step - loss: 4.9675e-04 - accuracy: 1.0000 - val_loss: 1.3238e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 4s 773ms/step - loss: 1.0770e-04 - accuracy: 1.0000 - val_loss: 6.4118e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 5s 963ms/step - loss: 4.9626e-05 - accuracy: 1.0000 - val_loss: 4.3490e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 4s 748ms/step - loss: 3.6063e-05 - accuracy: 1.0000 - val_loss: 3.4500e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 4s 757ms/step - loss: 2.8397e-05 - accuracy: 1.0000 - val_loss: 2.9900e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 6s 981ms/step - loss: 2.3741e-05 - accuracy: 1.0000 - val_loss: 2.7304e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 4s 762ms/step - loss: 2.1197e-05 - accuracy: 1.0000 - val_loss: 2.5655e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 5s 800ms/step - loss: 1.8864e-05 - accuracy: 1.0000 - val_loss: 2.4641e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 5s 844ms/step - loss: 1.7939e-05 - accuracy: 1.0000 - val_loss: 2.3840e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 4s 768ms/step - loss: 1.6362e-05 - accuracy: 1.0000 - val_loss: 2.3322e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 5s 971ms/step - loss: 1.5787e-05 - accuracy: 1.0000 - val_loss: 2.2825e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 4s 761ms/step - loss: 1.5098e-05 - accuracy: 1.0000 - val_loss: 2.2437e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 5s 808ms/step - loss: 1.4187e-05 - accuracy: 1.0000 - val_loss: 2.2146e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 7s 1s/step - loss: 1.3635e-05 - accuracy: 1.0000 - val_loss: 2.1907e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 4s 763ms/step - loss: 1.3278e-05 - accuracy: 1.0000 - val_loss: 2.1671e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 5s 806ms/step - loss: 1.2863e-05 - accuracy: 1.0000 - val_loss: 2.1453e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 5s 882ms/step - loss: 1.2485e-05 - accuracy: 1.0000 - val_loss: 2.1283e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 4s 760ms/step - loss: 1.2180e-05 - accuracy: 1.0000 - val_loss: 2.1103e-05 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = image.convert('RGB')\n",
        "    image = image.resize((224, 224), Image.BICUBIC)\n",
        "    image_array = np.array(image, dtype=np.float32) / 255.0\n",
        "    image_array = np.expand_dims(image_array, axis=0)\n",
        "    return image_array\n",
        "\n",
        "def load_images_and_labels(data_directory):\n",
        "    images, labels = [], []\n",
        "    list_of_people = sorted([name for name in os.listdir(data_directory) if os.path.isdir(os.path.join(data_directory, name)) and name != '.ipynb_checkpoints'])\n",
        "\n",
        "    for label, person in enumerate(list_of_people):\n",
        "        person_folder = os.path.join(data_directory, person)\n",
        "\n",
        "        for image_filename in os.listdir(person_folder):\n",
        "            if image_filename == '.ipynb_checkpoints' or not image_filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                continue\n",
        "            image_path = os.path.join(person_folder, image_filename)\n",
        "            image_array = preprocess_image(image_path)\n",
        "            images.append(image_array)\n",
        "            labels.append(label)\n",
        "\n",
        "    images = np.concatenate(images, axis=0)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels, list_of_people\n",
        "\n",
        "data_directory = '/content/drive/MyDrive/faces'\n",
        "images, labels, list_of_people = load_images_and_labels(data_directory)\n",
        "\n",
        "num_classes = len(list_of_people)\n",
        "\n",
        "# Use MobileNetV2 model\n",
        "mobilenet_v2_model = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", output_shape=[1280], trainable=False)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(224, 224, 3)),\n",
        "    mobilenet_v2_model,\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=20, batch_size=32)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WpZWugQlBKyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b200cc23-320c-4921-a3f2-4136b86ff934"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CcA657uqfQQ",
        "outputId": "28d4b7a9-3938-4f9e-82b0-3e9b5810b29d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "The person in the picture is: Logan\n"
          ]
        }
      ],
      "source": [
        "def recognize_person(image_path, model, list_of_people):\n",
        "    input_image = preprocess_image(image_path)\n",
        "    predictions = model.predict(input_image)\n",
        "    predicted_class_index = np.argmax(predictions[0])\n",
        "    return list_of_people[predicted_class_index]\n",
        "\n",
        "# Load a sample image for inference\n",
        "image_path = \"/content/drive/MyDrive/reader-test-person.png\"\n",
        "recognized_person = recognize_person(image_path, model, list_of_people)\n",
        "print(\"The person in the picture is:\", recognized_person)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4Xwn73Id5oM",
        "outputId": "c80f4b76-ff8d-4b97-928a-1a6213ed4bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        }
      ],
      "source": [
        "# Define the representative dataset\n",
        "def representative_dataset():\n",
        "    for i in range(len(train_images)):\n",
        "        yield([train_images[i].reshape(1, 224, 224, 3)])\n",
        "\n",
        "# Convert the model to a quantized TensorFlow Lite model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# Save the quantized TensorFlow Lite model to a file\n",
        "with open('/content/drive/MyDrive/face_recognition_quant.tflite', 'wb') as f:\n",
        "    f.write(tflite_quant_model)\n",
        "\n",
        "# Save the list_of_people to a CSV file\n",
        "with open('/content/drive/MyDrive/list_of_people.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    for person in list_of_people:\n",
        "        writer.writerow([person])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06ZMtreEKE-i",
        "outputId": "de493911-431a-4daf-872c-cfed40aa9242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2659  100  2659    0     0  42187      0 --:--:-- --:--:-- --:--:-- 42206\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,332 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [2,317 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [834 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,235 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [849 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,103 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 4,371 kB in 2s (2,225 kB/s)\n",
            "Reading package lists... Done\n",
            "W: https://packages.cloud.google.com/apt/dists/coral-edgetpu-stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  edgetpu-compiler\n",
            "0 upgraded, 1 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 7,913 kB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7,913 kB]\n",
            "Fetched 7,913 kB in 0s (31.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package edgetpu-compiler.\n",
            "(Reading database ... 120511 files and directories currently installed.)\n",
            "Preparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...\n",
            "Unpacking edgetpu-compiler (16.0) ...\n",
            "Setting up edgetpu-compiler (16.0) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n"
          ]
        }
      ],
      "source": [
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BqXERwLKIC9",
        "outputId": "eedc7090-a7c1-4f0b-a4cc-44bda8cc6a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge TPU Compiler version 16.0.384591198\n",
            "Started a compilation timeout timer of 180 seconds.\n",
            "\n",
            "Model compiled successfully in 1471 ms.\n",
            "\n",
            "Input model: /content/drive/MyDrive/face_recognition_quant.tflite\n",
            "Input size: 2.74MiB\n",
            "Output model: face_recognition_quant_edgetpu.tflite\n",
            "Output size: 2.94MiB\n",
            "On-chip memory used for caching model parameters: 2.79MiB\n",
            "On-chip memory remaining for caching model parameters: 4.89MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 64.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 69\n",
            "Operation log: face_recognition_quant_edgetpu.log\n",
            "See the operation log file for individual operation details.\n",
            "Compilation child process completed within timeout period.\n",
            "Compilation succeeded! \n"
          ]
        }
      ],
      "source": [
        "!edgetpu_compiler /content/drive/MyDrive/face_recognition_quant.tflite"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}